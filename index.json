[{"authors":["marcopavone"],"categories":null,"content":"Marco Pavone is Director of Autonomous Vehicle Research at NVIDIA. His main research interests are in the development of methodologies for the analysis, design, and control of autonomous systems, with an emphasis on self-driving cars, autonomous aerospace vehicles, and future mobility systems.\nHe is currently on partial leave from Stanford University, where he is an Associate Professor of Aeronautics and Astronautics. At Stanford, he is also the Director of the Autonomous Systems Laboratory and Co-Director of the Center for Automotive Research at Stanford. He received a Ph.D. degree in Aeronautics and Astronautics from the Massachusetts Institute of Technology in 2010.\nHe is a recipient of a number of awards, including a Presidential Early Career Award for Scientists and Engineers from President Barack Obama, an Office of Naval Research Young Investigator Award, a National Science Foundation Early Career (CAREER) Award, a NASA Early Career Faculty Award, and an Early-Career Spotlight Award from the Robotics Science and Systems Foundation. He was identified by the American Society for Engineering Education (ASEE) as one of America\u0026rsquo;s 20 most highly promising investigators under the age of 40. He is currently serving as an Associate Editor for the IEEE Control Systems Magazine.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"f8349c3a6aa2a880625c314b44491c1f","permalink":"/author/marco-pavone/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/marco-pavone/","section":"authors","summary":"Marco Pavone is Director of Autonomous Vehicle Research at NVIDIA. His main research interests are in the development of methodologies for the analysis, design, and control of autonomous systems, with an emphasis on self-driving cars, autonomous aerospace vehicles, and future mobility systems.","tags":null,"title":"Marco Pavone","type":"authors"},{"authors":["pasqualeantonante"],"categories":null,"content":"Pasquale Antonante is a Research Intern with the Autonomous Vehicle Research Group. He is also a Ph.D. candidate at the Massachusetts Institute of Technology (MIT), where he is advised by Prof. Luca Carlone. He obtained a B.Sc. degree in Computer Engineering from the University of Pisa, Italy, in 2014; and an S.M. degree (with honors) in Embedded Computing Systems from the Scuola Superiore Sant\u0026rsquo;Anna of Pisa, Italy, in 2017. Prior to MIT, he was a research scientist at the Raytheon Technologies Research Center in Cork (Ireland).\nHis research interests include safe and trustworthy robotic perception with applications to autonomous driving.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"bce8b89fe6b54c906ec9abe96efc2533","permalink":"/author/pasquale-antonante/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/pasquale-antonante/","section":"authors","summary":"Pasquale Antonante is a Research Intern with the Autonomous Vehicle Research Group. He is also a Ph.D. candidate at the Massachusetts Institute of Technology (MIT), where he is advised by Prof.","tags":null,"title":"Pasquale Antonante","type":"authors"},{"authors":["vincentcho"],"categories":null,"content":"My name is Vincent (Jang Hyun) Cho, a PhD student at the University of Texas at Austin (UT Austin) advised by Prof. Philipp Krähenbühl. I received my B.Sc. in Computer Science from Cornell University. My research interest is in computer vision, particularly in scaling recognition systems (2D, 3D object detection and segmentation). I focus on research topics such as long-tail, large/open-vocabulary detection, and training a unified model for multiple downstream tasks.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"74ca259b16c4e8c8bacf44a5bd4e26e2","permalink":"/author/vincent-cho/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/vincent-cho/","section":"authors","summary":"My name is Vincent (Jang Hyun) Cho, a PhD student at the University of Texas at Austin (UT Austin) advised by Prof. Philipp Krähenbühl. I received my B.Sc. in Computer Science from Cornell University.","tags":null,"title":"Vincent Cho","type":"authors"},{"authors":["wenhaoding"],"categories":null,"content":"Wenhao Ding is a Research Intern with the Autonomous Vehicle Research Group. He is concurrently pursuing a Ph.D. candidate at Carnegie Mellon University. He received a Master’s degree from Carnegie Mellon University and a B.S. degree from Tsinghua University.\nHis research interests lie in safety-critical scenario generation, causal reinforcement learning, and their applications within the fields of robotics and autonomous driving. Specifically, he proposes algorithms designed to improve robustness by training agents against semantic adversarial examples, and to enhance generalization to novel tasks by discovering the underlying causality of the physical world.\nFor more information, please check out his personal website.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"15c83c3951dc7c9941a252e06081c518","permalink":"/author/wenhao-ding/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/wenhao-ding/","section":"authors","summary":"Wenhao Ding is a Research Intern with the Autonomous Vehicle Research Group. He is concurrently pursuing a Ph.D. candidate at Carnegie Mellon University. He received a Master’s degree from Carnegie Mellon University and a B.","tags":null,"title":"Wenhao Ding","type":"authors"},{"authors":["andreabajcsy"],"categories":null,"content":"Andrea is a final-year Ph.D. candidate at University of California, Berkeley working with Anca Dragan and Claire Tomlin. She was a research intern with the group during Summer 2021.\nAndrea studies safe human-robot interaction, particularly when robots learn from and about people. Her research unites traditionally disparate methods from control theory and machine learning to develop theoretical frameworks and practical algorithms for human-robot interaction.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"296ddcd54813295b836543e7bd86577c","permalink":"/author/andrea-bajcsy/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/andrea-bajcsy/","section":"authors","summary":"Andrea is a final-year Ph.D. candidate at University of California, Berkeley working with Anca Dragan and Claire Tomlin. She was a research intern with the group during Summer 2021.\nAndrea studies safe human-robot interaction, particularly when robots learn from and about people.","tags":null,"title":"Andrea Bajcsy","type":"authors"},{"authors":["katieluo"],"categories":null,"content":"Katie is a Ph.D. student at Cornell University, advised by Prof. Kilian Q. Weinberger and Prof. Bharath Hariharan. Her research interests mostly lie in machine learning and computer vision for autonomous driving. Prior to her Ph.D, Katie was an AI Resident at Uber ATG (now part of Aurora), and she received a B.Sc. and M.S. in Electrical Engineering and Computer Science from the University of California, Berkeley.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"98e614d1a2d816158b0c9858d3e102d7","permalink":"/author/katie-luo/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/katie-luo/","section":"authors","summary":"Katie is a Ph.D. student at Cornell University, advised by Prof. Kilian Q. Weinberger and Prof. Bharath Hariharan. Her research interests mostly lie in machine learning and computer vision for autonomous driving.","tags":null,"title":"Katie Luo","type":"authors"},{"authors":["yulongcao"],"categories":null,"content":"Yulong Cao is a Research Intern with the Autonomous Vehicle Research Group. Yulong is a final year Ph.D. student in Computer Science and Engineering department from University of Michigan, advised by Morley Mao. He obtained his B.S. from University of Michigan and Shanghai Jiao Tong University in 2017. His research goal is to build secure and safe autonomous driving systems. His previous research sought to understand the vulnerability status of autonomous driving perception systems and how to secure it. His research interests broadly span machine learning security, sensor security, and cyber-physical systems security.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"b95ab538af621e2a706caff9e36fde35","permalink":"/author/yulong-cao/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/yulong-cao/","section":"authors","summary":"Yulong Cao is a Research Intern with the Autonomous Vehicle Research Group. Yulong is a final year Ph.D. student in Computer Science and Engineering department from University of Michigan, advised by Morley Mao.","tags":null,"title":"Yulong Cao","type":"authors"},{"authors":["gautamsingh"],"categories":null,"content":"Gautam Singh is a Research Intern with the Autonomous Vehicle Research Group at NVIDIA. He is pursuing a PhD at Rutgers University, advised by Sungjin Ahn. His interests center around learning representations and acquiring world models that can support out-of-distribution (OOD) generalization in neural networks. Towards this, he explores unsupervised approaches to harness the full potential of all available data. Before starting his PhD in 2018, he worked at IBM Research India after receiving a B.Tech. from the Indian Institute of Technology (IIT) Guwahati in 2015.\nFor more information, please check out his personal page.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"304de8e59bfe658dcf42be6cc3e00176","permalink":"/author/gautam-singh/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/gautam-singh/","section":"authors","summary":"Gautam Singh is a Research Intern with the Autonomous Vehicle Research Group at NVIDIA. He is pursuing a PhD at Rutgers University, advised by Sungjin Ahn. His interests center around learning representations and acquiring world models that can support out-of-distribution (OOD) generalization in neural networks.","tags":null,"title":"Gautam Singh","type":"authors"},{"authors":["gerryche"],"categories":null,"content":"Gerry obtained his B.S. in Mathematics from the University of Science and Technology of China, MSc in mathematics from University of Paris VI, MPhil in Machine Learning from University of Cambridge.\nHe completed his Ph.D. research in Deep Learning under the brilliant guidance of Prof. Yoshua Bengio at MILA. Prior to joining Nvidia, he interned at Google Brain, Salesforce Research and Element AI.\nGerry\u0026rsquo;s research interest centers around agent learning, generalization, safety critical learning and their applications in autonomous driving and robotics. He is currently exploring object-centric learning for agent learning applications.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"c3dab708cfdd817de77ba7cc3835e8a1","permalink":"/author/gerry-che/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/gerry-che/","section":"authors","summary":"Gerry obtained his B.S. in Mathematics from the University of Science and Technology of China, MSc in mathematics from University of Paris VI, MPhil in Machine Learning from University of Cambridge.","tags":null,"title":"Gerry Che","type":"authors"},{"authors":["yuxiaochen"],"categories":null,"content":"I am a research scientist associated with the autonomous vehicle research group at Nvidia. I\u0026rsquo;m interested in planning and decision making of safety-critical autonomous systems and multi-agent systems.\nI got my Bachelor\u0026rsquo;s degree from Tsinghua University in 2013 and my Ph.D. from University of Michigan in 2018. I spent 3 years as a postdoc at Caltech before joining Nvidia in 2021. I have worked on safety-critical control and planning for autonomous vehicles, ground and aerial robots, and power networks during my Ph.D. and postdoc years, and now I mainly focus on autonomous vehicles. My recent work concerns trajectory prediction and contingency planning for autonomous vehicles.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"a79eb01e0668d86595054a20269a48c1","permalink":"/author/yuxiao-chen/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/yuxiao-chen/","section":"authors","summary":"I am a research scientist associated with the autonomous vehicle research group at Nvidia. I\u0026rsquo;m interested in planning and decision making of safety-critical autonomous systems and multi-agent systems.\nI got my Bachelor\u0026rsquo;s degree from Tsinghua University in 2013 and my Ph.","tags":null,"title":"Yuxiao Chen","type":"authors"},{"authors":["shuhantan"],"categories":null,"content":"Shuhan Tan is a Research Intern with the Autonomous Vehicle Research Group at NVIDIA. He is pursuing a PhD at The University of Texas at Austin, advised by Professor Philipp Krähenbühl. His research interest mostly lies in machine learning and computer vision for autonomous driving, and particularly focuses on content generation for the safety of autonomous driving. His goal is to make autonomous driving safe and easily accessible. Prior to his Ph.D., Shuhan worked as a research intern at Uber ATG on autonomous driving. He received his B.S. from Sun Yat-sen University in Computer Science.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"8f39ad8f32ee2ccb8d1d2bedb1f1f11c","permalink":"/author/shuhan-tan/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/shuhan-tan/","section":"authors","summary":"Shuhan Tan is a Research Intern with the Autonomous Vehicle Research Group at NVIDIA. He is pursuing a PhD at The University of Texas at Austin, advised by Professor Philipp Krähenbühl.","tags":null,"title":"Shuhan Tan","type":"authors"},{"authors":["filipposchristianos"],"categories":null,"content":"Filippos is currently on an internship with the autonomous vehicle research group at NVIDIA. He is also a final year PhD student in the University of Edinburgh as a member of the autonomous agents research group.\nIn his internship, Filippos is working on reasoning and planning with occluded vehicles. His PhD is in the area of Multi-Agent Deep Reinforcement Learning. In particular, he studies how sharing experience can lead to efficient exploration, and how to share parameters in non-homogeneous environments.\nMore information can be found in his personal page.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"556765fba759cc06c98748920ef72bad","permalink":"/author/filippos-christianos/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/filippos-christianos/","section":"authors","summary":"Filippos is currently on an internship with the autonomous vehicle research group at NVIDIA. He is also a final year PhD student in the University of Edinburgh as a member of the autonomous agents research group.","tags":null,"title":"Filippos Christianos","type":"authors"},{"authors":["sandertonkens"],"categories":null,"content":"Sander Tonkens is a Research Intern with the Autonomous Vehicle Group for the Summer of 2023. He is also a Ph.D. student at University of California, San Diego (UCSD), where he is advised by Prof. Sylvia Herbert. He received his B.Sc. in Mechanical Engineering from Ecole Polytechnique Federale de Lausanne (EPFL) and his M.S. in Mechanical Engineering from Stanford University. Sander\u0026rsquo;s main research interests lie at the intersection of control theory and machine learning, aiming to provide probabilistic safe decision making for embodied AI systems.\nIn his spare time, Sander dabbles in almost all sports but particularly enjoys skiing, biking, backpacking, and surfing.\nFor more information, please check out his personal page.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"3c68cdcb89cb27c956ce74a1c333ea34","permalink":"/author/sander-tonkens/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/sander-tonkens/","section":"authors","summary":"Sander Tonkens is a Research Intern with the Autonomous Vehicle Group for the Summer of 2023. He is also a Ph.D. student at University of California, San Diego (UCSD), where he is advised by Prof.","tags":null,"title":"Sander Tonkens","type":"authors"},{"authors":["alecfarid"],"categories":null,"content":"I am a research intern at NVIDIA in the Autonomous Vehicles Research Group. I am also a Ph.D. candidate in the Mechanical and Aerospace Engineering Department at Princeton University advised by Anirudha Majumdar. I received my B.S. in Physics and Mathematics from Johns Hopkins University in 2018. I work on providing safety and performance guarantees for complex robotic systems when deployed in novel settings. I am also interested in determining when robots are unprepared to operate in the new settings.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"47572a77c3f12c584c1db120701c788a","permalink":"/author/alec-farid/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/alec-farid/","section":"authors","summary":"I am a research intern at NVIDIA in the Autonomous Vehicles Research Group. I am also a Ph.D. candidate in the Mechanical and Aerospace Engineering Department at Princeton University advised by Anirudha Majumdar.","tags":null,"title":"Alec Farid","type":"authors"},{"authors":["letianwang"],"categories":null,"content":"Letian Wang is a research intern with the Autonomous Vehicle Research Group. He is a Ph.D. student at the University of Toronto, supervised by Prof. Steven Waslander. He was previously a research assistant at UC Berkeley and Carnegie Mellon University, and received his Master\u0026rsquo;s and Bachelor\u0026rsquo;s degree from Beihang University in China.\nHis research interests lie in the intersection between autonomous driving, robotics, and machine learning, with current focuses on generalizable decision-making and behavior generation for autonomous driving. He was the winner of 2022 CARLA autonomous driving challenge, and won the best paper award honorable mention at RA-L 2021.\nFor more information, please check out his web page.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"f9034d790fa9f5e61a087e49f32e4109","permalink":"/author/letian-wang/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/letian-wang/","section":"authors","summary":"Letian Wang is a research intern with the Autonomous Vehicle Research Group. He is a Ph.D. student at the University of Toronto, supervised by Prof. Steven Waslander. He was previously a research assistant at UC Berkeley and Carnegie Mellon University, and received his Master\u0026rsquo;s and Bachelor\u0026rsquo;s degree from Beihang University in China.","tags":null,"title":"Letian Wang","type":"authors"},{"authors":["ryancosner"],"categories":null,"content":"Ryan Cosner is a Research Intern with the Autonomous Vehicle Research Group for the Summmer of 2022. He is also a PhD candidate at the California Institute of Technology (Caltech) where he is advised by Professor Aaron Ames. He obtained his B.S. from UC Berkeley in 2019 and his M.S. from Caltech in 2021. His main research interests are nonlinear control and machine learning and their applications to the control of robots and autonomous vehicles in uncertain and safety-critical environments.\nIn his spare time, Ryan enjoys playing music and racing triathlons.\nFor more information, please check out his personal page.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"da9f32149202d973cd025203c6599db3","permalink":"/author/ryan-cosner/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/ryan-cosner/","section":"authors","summary":"Ryan Cosner is a Research Intern with the Autonomous Vehicle Research Group for the Summmer of 2022. He is also a PhD candidate at the California Institute of Technology (Caltech) where he is advised by Professor Aaron Ames.","tags":null,"title":"Ryan Cosner","type":"authors"},{"authors":["tarungupta"],"categories":null,"content":"Tarun is a third year PhD student at University of Oxford, currently interning with autonomous vehicle research group at NVIDIA. His thesis focuses on improving the sample efficiency of cooperative multi-agent reinforcement learning (MARL) methods via transfer learning, role-based learning and solving MARL pathologies like relative overgeneralisation.\nDuring his internship, he will be working on leveraging large semantic models for novelty in RL. For more information, please see his personal website.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"19af2b1410c2b845b17a03df1dc75855","permalink":"/author/tarun-gupta/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/tarun-gupta/","section":"authors","summary":"Tarun is a third year PhD student at University of Oxford, currently interning with autonomous vehicle research group at NVIDIA. His thesis focuses on improving the sample efficiency of cooperative multi-agent reinforcement learning (MARL) methods via transfer learning, role-based learning and solving MARL pathologies like relative overgeneralisation.","tags":null,"title":"Tarun Gupta","type":"authors"},{"authors":["kaichiehhsu"],"categories":null,"content":"Kai-Chieh Hsu is a Research Intern in the Autonomous Vehicle Research Group. He is also a Ph.D. candidate in the Electrical and Computer Engineering Department at Princeton University advised by Jaime Fernández Fisac. He received his B.S. from National Taiwan University in 2019. He combines safety analysis and machine learning techniques to enable autonomous systems deployed in the physical world with many humans. His research interests span safe reinforcement learning, reachability analysis, and multi-agent systems.\nFor more information, please check out his personal website.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"68aee6bec7b9224b4b8fd0ff421c2ee2","permalink":"/author/kai-chieh-hsu/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/kai-chieh-hsu/","section":"authors","summary":"Kai-Chieh Hsu is a Research Intern in the Autonomous Vehicle Research Group. He is also a Ph.D. candidate in the Electrical and Computer Engineering Department at Princeton University advised by Jaime Fernández Fisac.","tags":null,"title":"Kai-Chieh Hsu","type":"authors"},{"authors":["jiaweiyang"],"categories":null,"content":"Jiawei Yang is a Research Intern with the Autonomous Vehicle Research Group at Nvidia Research. He completed his Master\u0026rsquo;s degree in Electrical and Computer Engineering from UCLA in 2023, and will begin his PhD at USC starting from Fall 2023.\nJiawei\u0026rsquo;s research interests center around neural representations, primarily Neural Radiance Fields (NeRF), and representation learning, with a particular emphasis on self-supervised learning. He is currently working on integrating NeRF and self-supervised learning into autonomous driving, aiming to build a general-purpose model for different driving tasks.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"b7a32a179b6b2ce836316587e07c8ae7","permalink":"/author/jiawei-yang/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/jiawei-yang/","section":"authors","summary":"Jiawei Yang is a Research Intern with the Autonomous Vehicle Research Group at Nvidia Research. He completed his Master\u0026rsquo;s degree in Electrical and Computer Engineering from UCLA in 2023, and will begin his PhD at USC starting from Fall 2023.","tags":null,"title":"Jiawei Yang","type":"authors"},{"authors":["borisivanovic"],"categories":null,"content":"Boris Ivanovic is a Senior Research Scientist and Manager in the Autonomous Vehicle Research Group. Prior to joining NVIDIA, he received his Ph.D. in Aeronautics and Astronautics under the supervision of Marco Pavone in 2021 and an M.S. in Computer Science in 2018, both from Stanford University. He received his B.A.Sc. in Engineering Science from the University of Toronto in 2016.\nBoris\u0026rsquo; research interests are rooted in trajectory forecasting and its interactions with the rest of the autonomy stack. This usually includes a mix of improving raw prediction performance, integrating prediction with perception and planning, and holistically evaluating autonomy stack performance. He has also previously conducted research in the fields of computer vision, natural language processing, and data science.\nIn his spare time, Boris enjoys playing tennis, skiing, hiking, traveling, watching docudramas, and cooking.\nFor more information, please check out his personal page.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"ae9a0cef27bf6096d020fa3eee9139c6","permalink":"/author/boris-ivanovic/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/boris-ivanovic/","section":"authors","summary":"Boris Ivanovic is a Senior Research Scientist and Manager in the Autonomous Vehicle Research Group. Prior to joining NVIDIA, he received his Ph.D. in Aeronautics and Astronautics under the supervision of Marco Pavone in 2021 and an M.","tags":null,"title":"Boris Ivanovic","type":"authors"},{"authors":["peterkarkus"],"categories":null,"content":"Peter is a Research Scientist at NVIDIA. Previously he has been a PhD candidate at the National University of Singapore, and he also held visiting research appointments at MIT and CMU.\nPeter\u0026rsquo;s research vision is to build human-level robot intelligence by combining structure and learning. His interests cover robotics, machine learning, and autonomous vehicles. His recent works are on neural networks that encode differentiable robot algorithms in order to learn partially observable planning, visual navigation, mapping and localization tasks.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"44d9f390a1710bdb72c577d0725296d9","permalink":"/author/peter-karkus/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/peter-karkus/","section":"authors","summary":"Peter is a Research Scientist at NVIDIA. Previously he has been a PhD candidate at the National University of Singapore, and he also held visiting research appointments at MIT and CMU.","tags":null,"title":"Peter Karkus","type":"authors"},{"authors":["boyili"],"categories":null,"content":"Boyi Li is a Research Scientist in the Autonomous Vehicle Research group at NVIDIA. She is broadly interested in the computer Vision, machine Learning and multimedia Art. Particularly, her research focuses on multimodal and data-efficient machine learning. Her research vision is to enable interactive, user-friendly and reliable autonomy for a broad range of high-integrity robotics applications. Prior to joining NVIDIA, received her Ph.D. at Cornell University, advised by Prof. Serge Belongie and Prof. Kilian Q. Weinberger.\nFor more information, please check out her personal page.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"d59bbe2d85524670a70d579b19325928","permalink":"/author/boyi-li/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/boyi-li/","section":"authors","summary":"Boyi Li is a Research Scientist in the Autonomous Vehicle Research group at NVIDIA. She is broadly interested in the computer Vision, machine Learning and multimedia Art. Particularly, her research focuses on multimodal and data-efficient machine learning.","tags":null,"title":"Boyi Li","type":"authors"},{"authors":["edschmerling"],"categories":null,"content":"Ed Schmerling is a Research Scientist in the Autonomous Vehicle Research Group at NVIDIA. His main research interests are in the modeling and development of intelligent data-driven agents through advances in generative modeling, uncertainty quantification, and optimal control with applications in simulation, behavior planning, and safety assurance. Prior to joining NVIDIA, he served as the Associate Director of the Autonomous Systems Laboratory at Stanford University, and has previously worked as an AV researcher at Waymo. He received a Ph.D. at the Institute for Computational and Mathematical Engineering (ICME) at Stanford in 2019.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"048d942359a66f7557ec400aa924b7fa","permalink":"/author/ed-schmerling/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/ed-schmerling/","section":"authors","summary":"Ed Schmerling is a Research Scientist in the Autonomous Vehicle Research Group at NVIDIA. His main research interests are in the modeling and development of intelligent data-driven agents through advances in generative modeling, uncertainty quantification, and optimal control with applications in simulation, behavior planning, and safety assurance.","tags":null,"title":"Ed Schmerling","type":"authors"},{"authors":["karenleung"],"categories":null,"content":"I am a research scientist working with NVIDIA\u0026rsquo;s Autonomous Vehicle Research Group. My research interests include safe and interaction-aware planning and control for autonomous vehicles, and developing structured and interpretable deep learning models grounded by logic.\nI received my Ph.D. and M.S. in Aeronautics and Astronautics from Stanford University. My Ph.D. dissertation, entitled \u0026ldquo;On Using Formal Methods for Safe and Robust Robot Autonomy,\u0026rdquo; leverages techniques from formal methods to provide safety assurances for a robot autonomy stack and build a computational paradigm to infuse logic into robot learning.\nCheck out my personal website to find out more.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"a681e19d52b1454c5033806d86563a90","permalink":"/author/karen-leung/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/karen-leung/","section":"authors","summary":"I am a research scientist working with NVIDIA\u0026rsquo;s Autonomous Vehicle Research Group. My research interests include safe and interaction-aware planning and control for autonomous vehicles, and developing structured and interpretable deep learning models grounded by logic.","tags":null,"title":"Karen Leung","type":"authors"},{"authors":["apoorvasharma"],"categories":null,"content":"Apoorva Sharma is a Research Scientist in the Autonomous Vehicles Group at NVIDIA Research. His research interests focus on quantifying uncertainty in machine learning, with application towards building safe ML-enabled autonomous systems.\nApoorva received his PhD and MS in Aeronautics and Astronautics from Stanford University. His PhD thesis, \u0026ldquo;Methods for Quantifying, Representing, and Utilizing Uncertainty in Learning-Enabled Autonomy,\u0026rdquo; proposed novel approaches to equip ML models with estimates of epistemic uncertainty, as well as algorithms for planning with uncertain models. Prior to attending Stanford, Apoorva received his BS in Engineering at Harvey Mudd College, where he was a member of the Lab for Autonomous and Intelligent Robotics, working on path planning for autonomous underwater vehicles.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"b3b1bfe817a3bf72201f98cc4fff432a","permalink":"/author/apoorva-sharma/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/apoorva-sharma/","section":"authors","summary":"Apoorva Sharma is a Research Scientist in the Autonomous Vehicles Group at NVIDIA Research. His research interests focus on quantifying uncertainty in machine learning, with application towards building safe ML-enabled autonomous systems.","tags":null,"title":"Apoorva Sharma","type":"authors"},{"authors":["fanyunsun"],"categories":null,"content":"Fan-Yun Sun is a Research Intern with the Autonomous Vehicle Research Group. He is a rising third-year Computer Science Ph.D. student at Stanford, advised by the amazing Nick Haber and Jiajun Wu. Previously, he had worked with Dan Yamins, Jure Leskovec, and Stefano Ermon during his first year at Stanford, Jian Tang at MILA, and Shou-De Lin at National Taiwan University (NTU) where he obtained his B.S..\nHe is interested in embodied AI, semantic scene understanding, and relational learning, His ultimate goal is to enable embodied AI agents to interact with their environment and other agents realistically and seamlessly.\nAside from research, Sun enjoys playing golf, table tennis, and poker.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"973a4e373fec5c50ccff789f09f6a4ff","permalink":"/author/fan-yun-sun/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/fan-yun-sun/","section":"authors","summary":"Fan-Yun Sun is a Research Intern with the Autonomous Vehicle Research Group. He is a rising third-year Computer Science Ph.D. student at Stanford, advised by the amazing Nick Haber and Jiajun Wu.","tags":null,"title":"Fan-Yun Sun","type":"authors"},{"authors":["sushantveer"],"categories":null,"content":"Sushant Veer is a Research Scientist with the Autonomous Vehicle Research Group at NVIDIA Research. In the past he was a Postdoctoral Research Associate in the Mechanical and Aerospace Engineering Department at Princeton University. He received his Ph.D. in Mechanical Engineering from the University of Delaware in 2018 and a B.Tech. in Mechanical Engineering from the Indian Institute of Technology Madras in 2013. His research interests lie at the intersection of control theory and machine learning with the goal of enabling safe decision making for robotic systems. Sushant is a recipient of the Yeongchi Wu International Education Award for his work on the development of a standing wheelchair at the International Society of Prosthetics and Orthotics World Congress, 2013. He has also received the Singapore Technologies Scholarship (ST Engineering Pte Ltd) and Sri Chinmay Deodhar Prize (Indian Institute of Technology Madras).\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"b33f44f90c6c397f37f6875231a72ac4","permalink":"/author/sushant-veer/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/sushant-veer/","section":"authors","summary":"Sushant Veer is a Research Scientist with the Autonomous Vehicle Research Group at NVIDIA Research. In the past he was a Postdoctoral Research Associate in the Mechanical and Aerospace Engineering Department at Princeton University.","tags":null,"title":"Sushant Veer","type":"authors"},{"authors":["yanwang"],"categories":null,"content":"Yan Wang works as a research scientist with NVIDIA\u0026rsquo;s Autonomous Driving Research Group. Prior to this, he was a research scientist at Waymo, where he worked on autonomous driving perception. He earned a Ph.D. in Computer Science from Cornell University, where he was advised by Professors Kilian Q. Weinberger and Bharath Hariharan. Yan\u0026rsquo;s research interests lie in computer vision and machine learning, with a recent focus on cost-effective autonomous driving perception. His work has included camera-based depth estimation, 3D detection using \u0026ldquo;pseudo-LiDAR\u0026rdquo;, tracking, behavior prediction, domain adaptation, and few-shot learning.\nPlease visit his personal website for more details.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"f51833042810e32c3a003d0e434c5140","permalink":"/author/yan-wang/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/yan-wang/","section":"authors","summary":"Yan Wang works as a research scientist with NVIDIA\u0026rsquo;s Autonomous Driving Research Group. Prior to this, he was a research scientist at Waymo, where he worked on autonomous driving perception. He earned a Ph.","tags":null,"title":"Yan Wang","type":"authors"},{"authors":["yuewang"],"categories":null,"content":"I am an incoming Assistant Professor at USC CS and a Research Scientist in the NVIDIA Research Autonomous Vehicle Research Group, working with Marco Pavone. I graduated from MIT EECS in 2022, advised by Justin Solomon in the Geometric Data Processing Group. I was also fortunate to collaborate with Michael Bronstein and Phillip Isola. Previously, I was a master student at the University of California, San Diego. Prior to that, I received my BEng in Computer Science from Zhejiang University. I’ve received the NVIDIA Fellowship (2020-2021) and the MIT EECS William A. Martin Master’s Thesis Award (2021).\nMy research lies at the intersection of computer vision, computer graphics, and robotics. My goal is to use machine learning to enable visual intelligence with minimal human supervision. I study how to design 3D learning systems which leverage geometry, appearance, and any other cues that are naturally available in sensory inputs. I am also broadly interested in eclectic applications on top of these systems.\nFor more information, please see my personal website.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"dbb186fb778012bea78689c19ab753cb","permalink":"/author/yue-wang/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/yue-wang/","section":"authors","summary":"I am an incoming Assistant Professor at USC CS and a Research Scientist in the NVIDIA Research Autonomous Vehicle Research Group, working with Marco Pavone. I graduated from MIT EECS in 2022, advised by Justin Solomon in the Geometric Data Processing Group.","tags":null,"title":"Yue Wang","type":"authors"},{"authors":["xinshuoweng"],"categories":null,"content":"Xinshuo Weng is a Ph.D. student (2018-) at the Robotics Institute of Carnegie Mellon University (CMU) advised by Kris Kitani and also currently a research intern at the NVIDIA Autonomous Vehicle Research group advised by Marco Pavone. She received master\u0026rsquo;s degree (2016-17) at CMU, where she worked with Yaser Sheikh and Kris Kitani. Prior to CMU, she worked at Facebook Reality Lab as a research engineer to help build \u0026ldquo;Photorealistic Telepresence\u0026rdquo;. Her bachelor was received from Wuhan University. Her research interest lies in 3D computer vision and Graph Neural Networks for autonomous systems. She has developed 3D multi-object tracking systems such as AB3DMOT that received \u0026gt;1,200 stars on GitHub. Also, she is leading a few autonomous driving workshops at major conferences such as NeurIPS 2021, IJCAI 2021, ICCV 2021 and IROS 2021. She was awarded a Qualcomm Innovation Fellowship for 2020 and a Facebook Fellowship Finalist for 2021.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"f715af690d6bf2cb41ac0d7c6a0c1d66","permalink":"/author/xinshuo-weng/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/xinshuo-weng/","section":"authors","summary":"Xinshuo Weng is a Ph.D. student (2018-) at the Robotics Institute of Carnegie Mellon University (CMU) advised by Kris Kitani and also currently a research intern at the NVIDIA Autonomous Vehicle Research group advised by Marco Pavone.","tags":null,"title":"Xinshuo Weng","type":"authors"},{"authors":["chaoweixiao"],"categories":null,"content":"Chaowei Xiao is an Assistant Professor at the University of Wisconsin, Madison and a Research Scientist in the Autonomous Vehicle Research group at NVIDIA. His research interests lie at the intersection of security, privacy, and machine learning, with the goal of building socially responsible machine learning systems. He is currently very interested in exploring trustworthiness in (MultiModal) Large Language Models and studying the role of LLMs in different application domains.\nPrior to joining NVIDIA, Chaowei received his Ph.D. from the Computer Science and Engineering Department at the University of Michigan, Ann Arbor in 2020, and his bachelor\u0026rsquo;s degree in the School of Software from Tsinghua University in 2015.\nFor more information, please check out his personal page.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"1793f75241fd44450c873ee08b83eec9","permalink":"/author/chaowei-xiao/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/chaowei-xiao/","section":"authors","summary":"Chaowei Xiao is an Assistant Professor at the University of Wisconsin, Madison and a Research Scientist in the Autonomous Vehicle Research group at NVIDIA. His research interests lie at the intersection of security, privacy, and machine learning, with the goal of building socially responsible machine learning systems.","tags":null,"title":"Chaowei Xiao","type":"authors"},{"authors":["danfeixu"],"categories":null,"content":"Danfei Xu is a Research Scientist with the Autonomous Vehicle Research Group. Prior to joining NVIDIA, Danfei obtained his Ph.D. in Computer Science from Stanford University in 2021, advised by Silvio Savarese and Fei-Fei Li. He obtained his B.S. from Columbia University in 2015. Danfei’s research is in robot learning. His research goal is to build autonomous systems that have human-like abilities to generalize to new tasks and environments. His Ph.D. work sought to endow robots with compositional generalization capabilities and solve long-horizon tasks in complex environments. Some examples are generalizable visual imitation learning using neural program induction and neural graph inference, compositional planning with neural-symbolic planners, learning abstract planning spaces, and discovering compositional representations from demonstrations.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"e5f35b910d4f8de7f02dbea83bf62637","permalink":"/author/danfei-xu/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/danfei-xu/","section":"authors","summary":"Danfei Xu is a Research Scientist with the Autonomous Vehicle Research Group. Prior to joining NVIDIA, Danfei obtained his Ph.D. in Computer Science from Stanford University in 2021, advised by Silvio Savarese and Fei-Fei Li.","tags":null,"title":"Danfei Xu","type":"authors"},{"authors":["ziyuanzhong"],"categories":null,"content":"Ziyuan Zhong is a Research Intern in the Autonomous Vehicle Research Group. He is also a Ph.D. candidate in the Computer Science Department at Columbia University advised by Baishakhi Ray. He received his B.A. and B.S. from Reed College and Columbia University, respectively, in 2019. His research focuses on testing/improving Autonomous Driving Systems (ADSs) and robustness of deep learning models.\nFor more information, please check out his personal website.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"81144525d97b4621b9724c3b77a3487d","permalink":"/author/ziyuan-zhong/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/ziyuan-zhong/","section":"authors","summary":"Ziyuan Zhong is a Research Intern in the Autonomous Vehicle Research Group. He is also a Ph.D. candidate in the Computer Science Department at Columbia University advised by Baishakhi Ray. He received his B.","tags":null,"title":"Ziyuan Zhong","type":"authors"},{"authors":["hengyang"],"categories":null,"content":"Heng Yang is a Research Scientist in the Autonomous Vehicle Research group at NVIDIA. He is broadly interested in the algorithmic foundations of robot perception, action, and learning. His research vision is to enable safe and trustworthy autonomy for a broad range of high-integrity robotics applications, by designing tractable and provably correct algorithms that enjoy rigorous performance guarantees, developing fast implementations, and validating them on real robotic systems. At NVIDIA research, Heng Yang is particularly interested in bringing safety assurances and robustness guarantees to modern learning-based perception modules towards trustworthy autonomous driving. Prior to joining NVIDIA, Heng Yang received his Ph.D. in Mechanical Engineering in 2022 under the supervision of Prof. Luca Carlone from the Laboratory for Information and Decision Systems at MIT. He obtained an M.S. in Mechanical Engineering in 2017 from MIT, and a B.E. in Automotive Engineering in 2015 from Tsinghua University.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"2196240a749256bc039e733b11a3d23b","permalink":"/author/heng-yang/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/heng-yang/","section":"authors","summary":"Heng Yang is a Research Scientist in the Autonomous Vehicle Research group at NVIDIA. He is broadly interested in the algorithmic foundations of robot perception, action, and learning. His research vision is to enable safe and trustworthy autonomy for a broad range of high-integrity robotics applications, by designing tractable and provably correct algorithms that enjoy rigorous performance guarantees, developing fast implementations, and validating them on real robotic systems.","tags":null,"title":"Heng Yang","type":"authors"},{"authors":["admin"],"categories":null,"content":"Welcome to the homepage of the NVIDIA Research Autonomous Vehicle Research Group led by Dr. Marco Pavone.\nWe are a newer team within NVIDIA Research that brings together a diverse and interdisciplinary set of researchers to address core topics in vehicle autonomy, ranging from perception and prediction to planning and control, as well as advance the state of the art in a number of critical related fields such as decision making under uncertainty, self-supervised learning, and the verification and validation of safety-critical AI systems.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"/author/autonomous-vehicle-research-group/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/autonomous-vehicle-research-group/","section":"authors","summary":"Welcome to the homepage of the NVIDIA Research Autonomous Vehicle Research Group led by Dr. Marco Pavone.\nWe are a newer team within NVIDIA Research that brings together a diverse and interdisciplinary set of researchers to address core topics in vehicle autonomy, ranging from perception and prediction to planning and control, as well as advance the state of the art in a number of critical related fields such as decision making under uncertainty, self-supervised learning, and the verification and validation of safety-critical AI systems.","tags":null,"title":"Autonomous Vehicle Research Group","type":"authors"},{"authors":["Shucheng Kang","Yuxiao Chen","Heng Yang","Marco Pavone"],"categories":null,"content":"","date":1690986119,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1690986119,"objectID":"94ab678888f44790c513e98477dc83cf","permalink":"/publication/kang.chen.etal.cdc2023/","publishdate":"2023-08-02T10:21:59-04:00","relpermalink":"/publication/kang.chen.etal.cdc2023/","section":"publication","summary":"We study the problem of verification and synthesis of robust control barrier functions (CBF) for control-affine polynomial systems with bounded additive uncertainty and convex polynomial constraints on the control. We first formulate robust CBF verification and synthesis as multilevel polynomial optimization problems (POP), where verification optimizes -- in three levels -- the uncertainty, control, and state, while synthesis additionally optimizes the parameter of a chosen parametric CBF candidate. We then show that, by invoking the KKT conditions of the inner optimizations over uncertainty and control, the verification problem can be simplified as a single-level POP and the synthesis problem reduces to a min-max POP. This reduction leads to multilevel semidefinite relaxations. For the verification problem, we apply Lasserre's hierarchy of moment relaxations. For the synthesis problem, we draw connections to existing relaxation techniques for robust min-max POP, which first use sum-of-squares programming to find increasingly tight polynomial lower bounds to the unknown value function of the verification POP, and then call Lasserre's hierarchy again to maximize the lower bounds. Both semidefinite relaxations guarantee asymptotic global convergence to optimality. We provide an in-depth study of our framework on the controlled Van der Pol Oscillator, both with and without additive uncertainty.","tags":[],"title":"Verification and Synthesis of Robust Control Barrier Functions: Multilevel Polynomial Optimization and Semidefinite Relaxation","type":"publication"},{"authors":["Kai-Chieh Hsu","Karen Leung","Yuxiao Chen","Jaime Fisac","Marco Pavone"],"categories":null,"content":"","date":1690896119,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1690896119,"objectID":"5df4ef17bf2cef3f4acd05fb0cb90831","permalink":"/publication/hsu.leung.etal.iros2023/","publishdate":"2023-08-01T09:21:59-04:00","relpermalink":"/publication/hsu.leung.etal.iros2023/","section":"publication","summary":"The ability to anticipate surrounding agents' behaviors is critical to enable safe and seamless autonomous vehicles (AVs). While phenomenological methods have successfully predicted future trajectories from scene context, these predictions lack interpretability. On the other hand, ontological approaches assume an underlying structure able to describe the interaction dynamics or agents' internal decision processes. Still, they often suffer from poor scalability or cannot reflect diverse human behaviors. This work proposes an interpretability framework for a phenomenological method through responsibility evaluations. We formulate responsibility as a measure of how much an agent takes into account the welfare of other agents through counterfactual reasoning. Additionally, this framework abstracts the computed responsibility sequences into different responsibility levels and grounds these latent levels into a trajectory prediction model. The proposed responsibility-based interpretability framework is modular and easily integrated into a wide range of prediction models. To demonstrate the utility of the proposed framework in providing added interpretability, we adapt an existing AV prediction model and perform a simulation study on a real-world nuScenes traffic dataset. Experimental results show that we can perform offline ex-post traffic analysis by incorporating the responsibility signal and rendering interpretable but accurate online trajectory predictions.","tags":[],"title":"Interpretable Trajectory Prediction for Autonomous Vehicles via Counterfactual Responsibility","type":"publication"},{"authors":["Wenhao Ding","Tong Che","Ding Zhao","Marco Pavone"],"categories":null,"content":"","date":1690086119,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1690086119,"objectID":"535ad2afd2c565465e67fd77929b66d5","permalink":"/publication/ding.che.etal.icml2023/","publishdate":"2023-07-23T00:21:59-04:00","relpermalink":"/publication/ding.che.etal.icml2023/","section":"publication","summary":"Recently, reward-conditioned reinforcement learning (RCRL) has gained popularity due to its simplicity, flexibility, and off-policy nature. However, we will show that current RCRL approaches are fundamentally limited and fail to address two critical challenges of RCRL -- improving generalization on high reward-to-go (RTG) inputs, and avoiding out-of-distribution (OOD) RTG queries during testing time. To address these challenges when training vanilla RCRL architectures, we propose Bayesian Reparameterized RCRL (BR-RCRL), a novel set of inductive biases for RCRL inspired by Bayes' theorem. BR-RCRL removes a core obstacle preventing vanilla RCRL from generalizing on high RTG inputs -- a tendency that the model treats different RTG inputs as independent values, which we term \"RTG Independence\". BR-RCRL also allows us to design an accompanying adaptive inference method, which maximizes total returns while avoiding OOD queries that yield unpredictable behaviors in vanilla RCRL methods. We show that BR-RCRL achieves state-of-the-art performance on the Gym-Mujoco and Atari offline RL benchmarks, improving upon vanilla RCRL by up to 11%.","tags":[],"title":"Bayesian Reparameterization of Reward-Conditioned Reinforcement Learning with Energy-based Models","type":"publication"},{"authors":["Pasquale Antonante","Sushant Veer","Karen Leung","Xinshuo Weng","Luca Carlone","Marco Pavone"],"categories":null,"content":"","date":1689171719,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1689171719,"objectID":"acb2c13f596fe4ef9169eef5e9c22ccf","permalink":"/publication/antonante.veer.etal.rss2023/","publishdate":"2023-07-12T10:21:59-04:00","relpermalink":"/publication/antonante.veer.etal.rss2023/","section":"publication","summary":"Safety and performance are key enablers for autonomous driving: on the one hand we want our autonomous vehicles (AVs) to be safe, while at the same time their performance (e.g., comfort or progression) is key to adoption. To effectively walk the tight-rope between safety and performance, AVs need to be risk-averse, but not entirely risk-avoidant. To facilitate safe-yet-performant driving, in this paper, we develop a task-aware risk estimator that assesses the risk a perception failure poses to the AV's motion plan. If the failure has no bearing on the safety of the AV's motion plan, then regardless of how egregious the perception failure is, our task-aware risk estimator considers the failure to have a low risk; on the other hand, if a seemingly benign perception failure severely impacts the motion plan, then our estimator considers it to have a high risk. In this paper, we propose a task-aware risk estimator to decide whether a safety maneuver needs to be triggered. To estimate the task-aware risk, first, we leverage the perception failure - detected by a perception monitor - to synthesize an alternative plausible model for the vehicle's surroundings. The risk due to the perception failure is then formalized as the \"relative\" risk to the AV's motion plan between the perceived and the alternative plausible scenario. We employ a statistical tool called copula, which models tail dependencies between distributions, to estimate this risk. The theoretical properties of the copula allow us to compute probably approximately correct (PAC) estimates of the risk. We evaluate our task-aware risk estimator using NuPlan and compare it with established baselines, showing that the proposed risk estimator achieves the best F1-score (doubling the score of the best baseline) and exhibits a good balance between recall and precision, i.e., a good balance of safety and performance.","tags":[],"title":"Task-Aware Risk Estimation of Perception Failures for Autonomous Vehicles","type":"publication"},{"authors":["Sever Topan","Yuxiao Chen","Edward Schmerling","Karen Leung","Jonas Nilsson","Michael Cox","Marco Pavone"],"categories":null,"content":"","date":1685888519,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1685888519,"objectID":"5aee3f3f5367fb5eee21b5c00e3f8e1e","permalink":"/publication/topan.chen.etal.iv2023/","publishdate":"2023-06-04T10:21:59-04:00","relpermalink":"/publication/topan.chen.etal.iv2023/","section":"publication","summary":"A critical task for developing safe autonomous driving stacks is to determine whether an obstacle is safety-critical, i.e., poses an imminent threat to the autonomous vehicle. Our previous work showed that Hamilton Jacobi reachability theory can be applied to compute interaction-dynamics-aware perception safety zones that better inform an ego vehicle's perception module which obstacles are considered safety-critical. For completeness, these zones are typically larger than absolutely necessary, forcing the perception module to pay attention to a larger collection of objects for the sake of conservatism. As an improvement, we propose a maneuver-based decomposition of our safety zones that leverages information about the ego maneuver to reduce the zone volume. In particular, we propose a \"temporal convolution\" operation that produces safety zones for specific ego maneuvers, thus limiting the ego's behavior to reduce the size of the safety zones. We show with numerical experiments that maneuver-based zones are significantly smaller (up to 76% size reduction) than the baseline while maintaining completeness.","tags":[],"title":"Refining Obstacle Perception Safety Zones via Maneuver-Based Decomposition","type":"publication"},{"authors":["Jiawei Yang","Marco Pavone","Yue Wang"],"categories":null,"content":"","date":1679372519,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1679372519,"objectID":"c28cfad3cf85e15529b0c2927433a689","permalink":"/publication/yang.pavone.etal.cvpr2023/","publishdate":"2023-03-21T00:21:59-04:00","relpermalink":"/publication/yang.pavone.etal.cvpr2023/","section":"publication","summary":"Novel view synthesis with sparse inputs is a challenging problem for neural radiance fields (NeRF). Recent efforts alleviate this challenge by introducing external supervision, such as pre-trained models and extra depth signals, and by non-trivial patch-based rendering. In this paper, we present Frequency regularized NeRF (FreeNeRF), a surprisingly simple baseline that outperforms previous methods with minimal modifications to the plain NeRF. We analyze the key challenges in few-shot neural rendering and find that frequency plays an important role in NeRF's training. Based on the analysis, we propose two regularization terms. One is to regularize the frequency range of NeRF's inputs, while the other is to penalize the near-camera density fields. Both techniques are ``free lunches'' at no additional computational cost. We demonstrate that even with one line of code change, the original NeRF can achieve similar performance as other complicated methods in the few-shot setting. FreeNeRF achieves state-of-the-art performance across diverse datasets, including Blender, DTU, and LLFF. We hope this simple baseline will motivate a rethinking of the fundamental role of frequency in NeRF's training under the low-data regime and beyond.","tags":[],"title":"FreeNeRF: Improving Few-shot Neural Rendering with Free Frequency Regularization","type":"publication"},{"authors":["Heng Yang","Marco Pavone"],"categories":null,"content":"","date":1679372519,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1679372519,"objectID":"157f55d9468d3ac532a1294fb8758bc6","permalink":"/publication/yang.pavone.cvpr2023/","publishdate":"2023-03-21T00:21:59-04:00","relpermalink":"/publication/yang.pavone.cvpr2023/","section":"publication","summary":"The two-stage object pose estimation paradigm first detects semantic keypoints on the image and then estimates the 6D pose by minimizing reprojection errors. Despite performing well on standard benchmarks, existing techniques offer no provable guarantees on the quality and uncertainty of the estimation. In this paper, we inject two fundamental changes, namely conformal keypoint detection and geometric uncertainty propagation, into the two-stage paradigm and propose the first pose estimator that endows an estimation with provable and computable worst-case error bounds. On one hand, conformal keypoint detection applies the statistical machinery of inductive conformal prediction to convert heuristic keypoint detections into circular or elliptical prediction sets that cover the groundtruth keypoints with a user-specified marginal probability (e.g., 90%). Geometric uncertainty propagation, on the other, propagates the geometric constraints on the keypoints to the 6D object pose, leading to a Pose UnceRtainty SEt (PURSE) that guarantees coverage of the groundtruth pose with the same probability. The PURSE, however, is a nonconvex set that does not directly lead to estimated poses and uncertainties. Therefore, we develop RANdom SAmple averaGing (RANSAG) to compute an average pose and apply semidefinite relaxation to upper bound the worst-case errors between the average pose and the groundtruth. On the LineMOD Occlusion dataset we demonstrate: (i) the PURSE covers the groundtruth with valid probabilities; (ii) the worst-case error bounds provide correct uncertainty quantification; and (iii) the average pose achieves better or similar accuracy as representative methods based on sparse keypoints.","tags":[],"title":"Object Pose Estimation with Statistical Guarantees: Conformal Keypoint Detection and Geometric Uncertainty Propagation","type":"publication"},{"authors":["Karen Leung","Sushant Veer","Edward Schmerling","Marco Pavone"],"categories":null,"content":"","date":1673842919,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1673842919,"objectID":"94120c3f22c64c37a111c1cb4d0d6939","permalink":"/publication/leung.veer.etal.acc2023/","publishdate":"2023-01-16T00:21:59-04:00","relpermalink":"/publication/leung.veer.etal.acc2023/","section":"publication","summary":"Evaluating the safety of an autonomous vehicle (AV) depends on the behavior of surrounding agents which can be heavily influenced by factors such as environmental context and informally-defined driving etiquette. A key challenge is in determining a minimum set of assumptions on what constitutes reasonable foreseeable behaviors of other road users for the development of AV safety models and techniques. In this paper, we propose a data-driven AV safety design methodology that first learns ''reasonable'' behavioral assumptions from data, and then synthesizes an AV safety concept using these learned behavioral assumptions. We borrow techniques from control theory, namely high order control barrier functions and Hamilton-Jacobi reachability, to provide inductive bias to aid interpretability, verifiability, and tractability of our approach. In our experiments, we learn an AV safety concept using demonstrations collected from a highway traffic-weaving scenario, compare our learned concept to existing baselines, and showcase its efficacy in evaluating real-world driving logs.","tags":[],"title":"Learning Autonomous Vehicle Safety Concepts from Demonstrations","type":"publication"},{"authors":["Danfei Xu","Yuxiao Chen","Boris Ivanovic","Marco Pavone"],"categories":null,"content":"","date":1673756519,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1673756519,"objectID":"56ff314eeb842cf3ee14a4c65e8701f8","permalink":"/publication/xu.chen.etal.icra2023/","publishdate":"2023-01-15T00:21:59-04:00","relpermalink":"/publication/xu.chen.etal.icra2023/","section":"publication","summary":"Simulation is the key to scaling up validation and verification for robotic systems such as autonomous vehicles. Despite advances in high-fidelity physics and sensor simulation, a critical gap remains in simulating realistic behaviors of road users. This is because, unlike simulating physics and graphics, devising first principle models for human-like behaviors is generally infeasible. In this work, we take a data-driven approach and propose a method that can learn to generate traffic behaviors from real-world driving logs. The method achieves high sample efficiency and behavior diversity by exploiting the bi-level hierarchy of driving behaviors by decoupling the traffic simulation problem into high-level intent inference and low-level driving behavior imitation. The method also incorporates a planning module to obtain stable long-horizon behaviors. We empirically validate our method, named Bi-level Imitation for Traffic Simulation (BITS), with scenarios from two large-scale driving datasets and show that BITS achieves balanced traffic simulation performance in realism, diversity, and long-horizon stability. We also explore ways to evaluate behavior realism and introduce a suite of evaluation metrics for traffic simulation. Finally, as part of our core contributions, we develop and open source a software tool that unifies data formats across different driving datasets and converts scenes from existing datasets into interactive simulation environments.","tags":[],"title":"BITS: Bi-level Imitation for Traffic Simulation","type":"publication"},{"authors":["Boris Ivanovic","James Harrison","Marco Pavone"],"categories":null,"content":"","date":1673756519,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1673756519,"objectID":"645571625a18fe4d95825bc436c9a46a","permalink":"/publication/ivanovic.harrison.etal.icra2023/","publishdate":"2023-01-15T00:21:59-04:00","relpermalink":"/publication/ivanovic.harrison.etal.icra2023/","section":"publication","summary":"Learning-based behavior prediction methods are increasingly being deployed in real-world autonomous systems, e.g., in fleets of self-driving vehicles, which are beginning to commercially operate in major cities across the world. Despite their advancements, however, the vast majority of prediction systems are specialized to a set of well-explored geographic regions or operational design domains, complicating deployment to additional cities, countries, or continents. Towards this end, we present a novel method for efficiently adapting behavior prediction models to new environments. Our approach leverages recent advances in meta-learning, specifically Bayesian regression, to augment existing behavior prediction models with an adaptive layer that enables efficient domain transfer via offline fine-tuning, online adaptation, or both. Experiments across multiple real-world datasets demonstrate that our method can efficiently adapt to a variety of unseen environments.","tags":[],"title":"Expanding the Deployment Envelope of Behavior Prediction via Adaptive Meta-Learning","type":"publication"},{"authors":["Ziyuan Zhong","Davis Rempe","Danfei Xu","Yuxiao Chen","Sushant Veer","Tong Che","Baishakhi Ray","Marco Pavone"],"categories":null,"content":"","date":1673756519,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1673756519,"objectID":"35d0163218c89b44f7c98060da68acc4","permalink":"/publication/zhong.rempe.etal.icra2023/","publishdate":"2023-01-15T00:21:59-04:00","relpermalink":"/publication/zhong.rempe.etal.icra2023/","section":"publication","summary":"Controllable and realistic traffic simulation is critical for developing and verifying autonomous vehicles. Typical heuristic-based traffic models offer flexible control to make vehicles follow specific trajectories and traffic rules. On the other hand, data-driven approaches generate realistic and human-like behaviors, improving transfer from simulated to real-world traffic. However, to the best of our knowledge, no traffic model offers both controllability and realism. In this work, we develop a conditional diffusion model for controllable traffic generation (CTG) that allows users to control desired properties of trajectories at test time (e.g., reach a goal or follow a speed limit) while maintaining realism and physical feasibility through enforced dynamics. The key technical idea is to leverage recent advances from diffusion modeling and differentiable logic to guide generated trajectories to meet rules defined using signal temporal logic (STL). We further extend guidance to multi-agent settings and enable interaction-based rules like collision avoidance. CTG is extensively evaluated on the nuScenes dataset for diverse and composite rules, demonstrating improvement over strong baselines in terms of the controllability-realism tradeoff.","tags":[],"title":"Guided Conditional Diffusion for Controllable Traffic Simulation","type":"publication"},{"authors":["Filippos Christianos","Peter Karkus","Boris Ivanovic","Stefano V. Albrecht","Marco Pavone"],"categories":null,"content":"","date":1673756519,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1673756519,"objectID":"d829c3888738a4d5d5f514c08c9ee824","permalink":"/publication/christianos.karkus.etal.icra2023/","publishdate":"2023-01-15T00:21:59-04:00","relpermalink":"/publication/christianos.karkus.etal.icra2023/","section":"publication","summary":"Reasoning with occluded traffic agents is a significant open challenge for planning for autonomous vehicles. Recent deep learning models have shown impressive results for predicting occluded agents based on the behaviour of nearby visible agents; however, as we show in experiments, these models are difficult to integrate into downstream planning. To this end, we propose Bi-level Variational Occlusion Models (BiVO), a two-step generative model that first predicts likely locations of occluded agents, and then generates likely trajectories for the occluded agents. In contrast to existing methods, BiVO outputs a trajectory distribution which can then be sampled from and integrated into standard downstream planning. We evaluate the method in closed-loop replay simulation using the real-world nuScenes dataset. Our results suggest that BiVO can successfully learn to predict occluded agent trajectories, and these predictions lead to better subsequent motion plans in critical scenarios.","tags":[],"title":"Planning with Occluded Traffic Agents using Bi-Level Variational Occlusion Models","type":"publication"},{"authors":["Sushant Veer","Karen Leung","Ryan Cosner","Yuxiao Chen","Marco Pavone"],"categories":null,"content":"","date":1673756519,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1673756519,"objectID":"d1bf930869ee13abe0ec2831f2f2c9fe","permalink":"/publication/veer.leung.etal.icra2023/","publishdate":"2023-01-15T00:21:59-04:00","relpermalink":"/publication/veer.leung.etal.icra2023/","section":"publication","summary":"Autonomous vehicles must often contend with conflicting planning requirements, e.g., safety and comfort could be at odds with each other if avoiding a collision calls for slamming the brakes. To resolve such conflicts, assigning importance ranking to rules (i.e., imposing a rule hierarchy) has been proposed, which, in turn, induces rankings on trajectories based on the importance of the rules they satisfy. On one hand, imposing rule hierarchies can enhance interpretability, but introduce combinatorial complexity to planning; while on the other hand, differentiable reward structures can be leveraged by modern gradient-based optimization tools, but are less interpretable and unintuitive to tune. In this paper, we present an approach to equivalently express rule hierarchies as differentiable reward structures amenable to modern gradient-based optimizers, thereby, achieving the best of both worlds. We achieve this by formulating rank-preserving reward functions that are monotonic in the rank of the trajectories induced by the rule hierarchy; i.e., higher ranked trajectories receive higher reward. Equipped with a rule hierarchy and its corresponding rank-preserving reward function, we develop a two-stage planner that can efficiently resolve conflicting planning requirements. We demonstrate that our approach can generate motion plans in 7-10 Hz for various challenging road navigation and intersection negotiation scenarios.","tags":[],"title":"Receding Horizon Planning with Rule Hierarchies for Autonomous Vehicles","type":"publication"},{"authors":["Yuxiao Chen","Peter Karkus","Boris Ivanovic","Xinshuo Weng","Marco Pavone"],"categories":null,"content":"","date":1673756519,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1673756519,"objectID":"a753f8f493f8a157c5323654d418c7e8","permalink":"/publication/chen.karkus.etal.icra2023/","publishdate":"2023-01-15T00:21:59-04:00","relpermalink":"/publication/chen.karkus.etal.icra2023/","section":"publication","summary":"Autonomous vehicles (AVs) need to reason about the multimodal behavior of neighboring agents while planning their own motion. Many existing trajectory planners seek a single trajectory that performs well under all plausible futures simultaneously, ignoring bi-directional interactions and thus leading to overly conservative plans. Policy planning, whereby the ego agent plans a policy that reacts to the environment's multimodal behavior, is a promising direction as it can account for the action-reaction interactions between the AV and the environment. However, most existing policy planners do not scale to the complexity of real autonomous vehicle applications: they are either not compatible with modern deep learning prediction models, not interpretable, or not able to generate high quality trajectories. To fill this gap, we propose Tree Policy Planning (TPP), a policy planner that is compatible with state-of-the-art deep learning prediction models, generates multistage motion plans, and accounts for the influence of ego agent on the environment behavior. The key idea of TPP is to reduce the continuous optimization problem into a tractable discrete MDP through the construction of two tree structures: an ego trajectory tree for ego trajectory options, and a scenario tree for multi-modal ego-conditioned environment predictions. We demonstrate the efficacy of TPP in closed-loop simulations based on real-world nuScenes dataset and results show that TPP scales to realistic AV scenarios and significantly outperforms non-policy baselines.","tags":[],"title":"Tree-structured Policy Planning with Learned Behavior Models","type":"publication"},{"authors":["Ruixiang Zhang","Tong Che","Boris Ivanovic","Renhao Wang","Marco Pavone","Yoshua Bengio","Liam Paull"],"categories":null,"content":"","date":1673670119,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1673670119,"objectID":"f2eb150517d2cfc71930bb3c711f2890","permalink":"/publication/zhang.che.etal.iclr2023/","publishdate":"2023-01-14T00:21:59-04:00","relpermalink":"/publication/zhang.che.etal.iclr2023/","section":"publication","summary":"Humans are remarkably good at understanding and reasoning about complex visual scenes. The capability to decompose low-level observations into discrete objects allows us to build a grounded abstract representation and identify the compositional structure of the world. Accordingly, it is a crucial step for machine learning models to be capable of inferring objects and their properties from visual scenes without explicit supervision. However, existing works on object-centric representation learning either rely on tailor-made neural network modules or strong probabilistic assumptions in the underlying generative and inference processes. In this work, we present EGO, a conceptually simple and general approach to learning object-centric representations through an energy-based model. By forming a permutation-invariant energy function using vanilla attention blocks readily available in Transformers, we can infer object-centric latent variables via gradient-based MCMC methods where permutation equivariance is automatically guaranteed. We show that EGO can be easily integrated into existing architectures and can effectively extract high-quality object-centric representations, leading to better segmentation accuracy and competitive downstream task performance. Further, empirical evaluations show that EGO's learned representations are robust against distribution shift. Finally, we demonstrate the effectiveness of EGO in systematic compositional generalization, by re-composing learned energy functions for novel scene generation and manipulation.","tags":[],"title":"Robust and Controllable Object-Centric Learning through Energy-based Models","type":"publication"},{"authors":["Yulong Cao","Danfei Xu","Xinshuo Weng","Z. Morley Mao","Anima Anandkumar","Chaowei Xiao","Marco Pavone"],"categories":null,"content":"","date":1663942919,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1663942919,"objectID":"2bd85da8a8fe8bdd60123220e943a8f0","permalink":"/publication/cao.xu.etal.corl2022/","publishdate":"2022-09-23T10:21:59-04:00","relpermalink":"/publication/cao.xu.etal.corl2022/","section":"publication","summary":"Trajectory prediction using deep neural networks (DNNs) is an essential component of autonomous driving (AD) systems. However, these methods are vulnerable to adversarial attacks, leading to serious consequences such as collisions. In this work, we identify two key ingredients to defend trajectory prediction models against adversarial attacks including (1) designing effective adversarial training methods and (2) adding domain-specific data augmentation to mitigate the performance degradation on clean data. We demonstrate that our method is able to improve the performance by 46% on adversarial data and at the cost of only 3% performance degradation on clean data, compared to the model trained with clean data. Additionally, compared to existing robust methods, our method can improve performance by 21% on adversarial examples and 9% on clean data. Our robust model is evaluated with a planner to study its downstream impacts. We demonstrate that our model can significantly reduce the severe accident rates (e.g., collisions and off-road driving).","tags":[],"title":"Robust Trajectory Prediction against Adversarial Attacks","type":"publication"},{"authors":["Peter Karkus","Boris Ivanovic","Shie Mannor","Marco Pavone"],"categories":null,"content":"","date":1663939319,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1663939319,"objectID":"59f88de848c4c2278614d5d66e9068c4","permalink":"/publication/karkus.ivanovic.etal.corl2022/","publishdate":"2022-09-23T09:21:59-04:00","relpermalink":"/publication/karkus.ivanovic.etal.corl2022/","section":"publication","summary":"Autonomous vehicle (AV) stacks are typically built in a modular fashion, with explicit components performing detection, tracking, prediction, planning, control, etc. While modularity improves reusability, interpretability, and generalizability, it also suffers from compounding errors, information bottlenecks, and integration challenges. To overcome these challenges, a prominent approach is to convert the AV stack into an end-to-end neural network and train it with data. While such approaches have achieved impressive results, they typically lack interpretability and reusability, and they eschew principled analytical components, such as planning and control, in favor of deep neural networks. To enable the joint optimization of AV stacks while retaining modularity, we present DiffStack, a differentiable and modular stack for prediction, planning, and control. Crucially, our model-based planning and control algorithms leverage recent advancements in differentiable optimization to produce gradients, enabling optimization of upstream components, such as prediction, via backpropagation through planning and control. Our results on the nuScenes dataset indicate that end-to-end training with DiffStack yields substantial improvements in open-loop planning metrics by, e.g., learning to make fewer prediction errors that would affect planning. Beyond these immediate benefits, DiffStack opens up new opportunities for fully data-driven yet modular and interpretable AV architectures.","tags":[],"title":"DiffStack: A Differentiable and Modular Control Stack for Autonomous Vehicles","type":"publication"},{"authors":["Alec Farid","Sushant Veer","Boris Ivanovic","Karen Leung","Marco Pavone"],"categories":null,"content":"","date":1663939319,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1663939319,"objectID":"0904c54ecc7f8458129d80f305b11182","permalink":"/publication/farid.veer.etal.corl2022/","publishdate":"2022-09-23T09:21:59-04:00","relpermalink":"/publication/farid.veer.etal.corl2022/","section":"publication","summary":"In modern autonomy stacks, prediction modules are paramount to planning motions in the presence of other mobile agents. However, failures in prediction modules can mislead the downstream planner into making unsafe decisions. Indeed, the high uncertainty inherent to the task of trajectory forecasting ensures that such mispredictions occur frequently. Motivated by the need to improve safety of autonomous vehicles without compromising on their performance, we develop a probabilistic run-time monitor that detects when a harmful prediction failure occurs, i.e., a task-relevant failure detector. We achieve this by propagating trajectory prediction errors to the planning cost to reason about their impact on the AV. Furthermore, our detector comes equipped with performance measures on the false-positive and the false-negative rate and allows for data-free calibration. In our experiments we compared our detector with various others and found that our detector has the highest area under the receiver operator characteristic curve.","tags":[],"title":"Task-Relevant Failure Detection for Trajectory Predictors in Autonomous Vehicles","type":"publication"},{"authors":["Yulong Cao","Chaowei Xiao","Anima Anandkumar","Danfei Xu","Marco Pavone"],"categories":null,"content":"","date":1663856519,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1663856519,"objectID":"5f9e9dc8148b0f634e7fbb0412df7ef8","permalink":"/publication/cao.xiao.etal.eccv2022/","publishdate":"2022-09-22T10:21:59-04:00","relpermalink":"/publication/cao.xiao.etal.eccv2022/","section":"publication","summary":"Trajectory prediction is essential for autonomous vehicles (AVs) to plan correct and safe driving behaviors. While many prior works aim to achieve higher prediction accuracy, few study the adversarial robustness of their methods. To bridge this gap, we propose to study the adversarial robustness of data-driven trajectory prediction systems. We devise an optimization-based adversarial attack framework that leverages a carefully-designed differentiable dynamic model to generate realistic adversarial trajectories. Empirically, we benchmark the adversarial robustness of state-of-the-art prediction models and show that our attack increases the prediction error for both general metrics and planning-aware metrics by more than 50% and 37%. We also show that our attack can lead an AV to drive off road or collide into other vehicles in simulation. Finally, we demonstrate how to mitigate the adversarial attacks using an adversarial training scheme.","tags":[],"title":"AdvDO: Realistic Adversarial Attacks for Trajectory Prediction","type":"publication"},{"authors":["Karen Leung","Andrea Bajcsy","Edward Schmerling","Marco Pavone"],"categories":null,"content":"","date":1653056519,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1653056519,"objectID":"e180247d8312f199e18e9021483510ec","permalink":"/publication/leung.bajcsy.etal.arxiv2022/","publishdate":"2022-05-20T10:21:59-04:00","relpermalink":"/publication/leung.bajcsy.etal.arxiv2022/","section":"publication","summary":"As safety-critical autonomous vehicles (AVs) will soon become pervasive in our society, a number of safety concepts for trusted AV deployment have recently been proposed throughout industry and academia. Yet, achieving consensus on an appropriate safety concept is still an elusive task. In this paper, we advocate for the use of Hamilton-Jacobi (HJ) reachability as a unifying mathematical framework for comparing existing safety concepts, and through elements of this framework propose ways to tailor safety concepts (and thus expand their applicability) to scenarios with implicit expectations on agent behavior in a data-driven fashion. Specifically, we show that (i) existing predominant safety concepts can be embedded in the HJ reachability framework, thereby enabling a common language for comparing and contrasting modeling assumptions, and (ii) HJ reachability can serve as an inductive bias to effectively reason, in a learning context, about two critical, yet often overlooked aspects of safety: responsibility and context-dependency.","tags":[],"title":"Towards Data-Driven Synthesis of Autonomous Vehicle Safety Concepts","type":"publication"},{"authors":["Boris Ivanovic","Richard Lin","Shubham Shrivastava","Punarjay Chakravarty","Marco Pavone"],"categories":null,"content":"","date":1645539719,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1645539719,"objectID":"745196eca410cc04a2b6ffba2c223012","permalink":"/publication/ivanovic.lin.etal.icra2022/","publishdate":"2022-02-22T10:21:59-04:00","relpermalink":"/publication/ivanovic.lin.etal.icra2022/","section":"publication","summary":"Uncertainty pervades through the modern robotic autonomy stack, with nearly every component (e.g., sensors, detection, classification, tracking, behavior prediction) producing continuous or discrete probabilistic distributions. Trajectory forecasting, in particular, is surrounded by uncertainty as its inputs are produced by (noisy) upstream perception and its outputs are predictions that are often probabilistic for use in downstream planning. However, most trajectory forecasting methods do not account for upstream uncertainty, instead taking only the most-likely values. As a result, perceptual uncertainties are not propagated through forecasting and predictions are frequently overconfident. To address this, we present a novel method for incorporating perceptual state uncertainty in trajectory forecasting, a key component of which is a new statistical distance-based loss function which encourages predicting uncertainties that better match upstream perception. We evaluate our approach both in illustrative simulations and on large-scale, real-world data, demonstrating its efficacy in propagating perceptual state uncertainty through prediction and producing more calibrated predictions.","tags":[],"title":"Propagating State Uncertainty Through Trajectory Forecasting","type":"publication"},{"authors":["Yuxiao Chen","Boris Ivanovic","Marco Pavone"],"categories":null,"content":"","date":1645539719,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1645539719,"objectID":"289dee7a35d2930e47641c53f19ff358","permalink":"/publication/chen.ivanovic.etal.cvpr2022/","publishdate":"2022-02-22T10:21:59-04:00","relpermalink":"/publication/chen.ivanovic.etal.cvpr2022/","section":"publication","summary":"Trajectory prediction is a critical functionality of autonomous systems that share environments with uncontrolled agents, one prominent example being self-driving vehicles. Currently, most prediction methods do not enforce scene consistency, i.e., there are a substantial amount of self-collisions between predicted trajectories of different agents in the scene. Moreover, many approaches generate individual trajectory predictions per agent instead of joint trajectory predictions of the whole scene, which makes downstream planning difficult. In this work, we present ScePT, a policy planning-based trajectory prediction model that generates accurate, scene-consistent trajectory predictions suitable for autonomous system motion planning. It explicitly enforces scene consistency and learns an agent interaction policy that can be used for conditional prediction. Experiments on multiple real-world pedestrians and autonomous vehicle datasets show that ScePT matches current state-of-the-art prediction accuracy with significantly improved scene consistency. We also demonstrate ScePT's ability to work with a downstream contingency planner.","tags":[],"title":"ScePT: Scene-consistent, Policy-based Trajectory Predictions for Planning","type":"publication"},{"authors":["Xinshuo Weng","Boris Ivanovic","Kris Kitani","Marco Pavone"],"categories":null,"content":"","date":1645539719,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1645539719,"objectID":"8886177c76ddca7275c1da89b8a41b01","permalink":"/publication/weng.ivanovic.etal.cvpr2022/","publishdate":"2022-02-22T10:21:59-04:00","relpermalink":"/publication/weng.ivanovic.etal.cvpr2022/","section":"publication","summary":"Multi-agent trajectory prediction is critical for planning and decision-making in human-interactive autonomous systems, such as self-driving cars. However, most prediction models are developed separately from their upstream perception (detection and tracking) modules, assuming ground truth past trajectories as inputs. As a result, their performance degrades significantly when using real-world noisy tracking results as inputs. This is typically caused by the propagation of errors from tracking to prediction, such as noisy tracks, fragments and identity switches. To alleviate this propagation of errors, we propose a new prediction pipeline that only requires detections and their affinity matrices across frames as inputs, entirely removing the need for error-prone data association during tracking. Since affinity matrices contain 'soft' information about the similarity and identity of detections across frames, predicting directly from them retains strictly more information than using the tracklets generated by data association in tracking. Thorough experiments on large-scale, real-world autonomous driving datasets show that our affinity-based prediction scheme reduces overall prediction errors by up to 60.2%, in comparison to standard prediction pipelines that use tracklets as inputs, with even more significant error reduction (up to 88.2%) if restricting the evaluation to challenging scenarios with tracking errors.","tags":[],"title":"Whose Track Is It Anyway? Improving Robustness to Tracking Errors with Affinity-Based Prediction","type":"publication"},{"authors":["Sever Topan","Karen Leung","Yuxiao Chen","Pritish Tupekar","Edward Schmerling","Jonas Nilsson","Michael Cox","Marco Pavone"],"categories":null,"content":"","date":1634998919,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1634998919,"objectID":"bc2f2c5070a0f8eea0ae8a0c0edfedab","permalink":"/publication/topan.leung.etal.iv2022/","publishdate":"2021-10-23T10:21:59-04:00","relpermalink":"/publication/topan.leung.etal.iv2022/","section":"publication","summary":"To enable safe autonomous vehicle (AV) operations, it is critical that an AV's obstacle detection module can reliably detect obstacles that pose a safety threat (i.e., are safety-critical). It is therefore desirable that the evaluation metric for the perception system captures the safety-criticality of objects. Unfortunately, existing perception evaluation metrics tend to make strong assumptions about the objects and ignore the dynamic interactions between agents, and thus do not accurately capture the safety risks in reality. To address these shortcomings, we introduce an interaction-dynamics-aware obstacle detection evaluation metric by accounting for closed-loop dynamic interactions between an ego vehicle and obstacles in the scene. By borrowing existing theory from optimal control theory, namely Hamilton-Jacobi reachability, we present a computationally tractable method for constructing a ''safety zone'': a region in state space that defines where safety-critical obstacles lie for the purpose of defining safety metrics. Our proposed safety zone is mathematically complete, and can be easily computed to reflect a variety of safety requirements. Using an off-the-shelf detection algorithm from the nuScenes detection challenge leaderboard, we demonstrate that our approach is computationally lightweight, and can better capture safety-critical perception errors than a baseline approach.","tags":[],"title":"Interaction-Dynamics-Aware Perception Zones for Obstacle Detection Safety Evaluation","type":"publication"},{"authors":["Xinshuo Weng","Boris Ivanovic","Marco Pavone"],"categories":null,"content":"","date":1634566919,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1634566919,"objectID":"87dfa6aa5c9d97dc9792a881baac2f8e","permalink":"/publication/weng.ivanovic.etal.iv2022/","publishdate":"2021-10-18T10:21:59-04:00","relpermalink":"/publication/weng.ivanovic.etal.iv2022/","section":"publication","summary":"Recently, there has been tremendous progress in developing each individual module of the standard perception-planning robot autonomy pipeline, including detection, tracking, prediction of other agents' trajectories, and ego-agent trajectory planning. Nevertheless, there has been less attention given to the principled integration of these components, particularly in terms of the characterization and mitigation of cascading errors. This paper addresses the problem of cascading errors by focusing on the coupling between the tracking and prediction modules. First, by using state-of-the-art tracking and prediction tools, we conduct a comprehensive experimental evaluation of how severely errors stemming from tracking can impact prediction performance. On the KITTI and nuScenes datasets, we find that predictions consuming tracked trajectories as inputs (the typical case in practice) can experience a significant (even order of magnitude) drop in performance in comparison to the idealized setting where ground truth past trajectories are used as inputs. To address this issue, we propose a multi-hypothesis tracking and prediction framework. Rather than relying on a single set of tracking results for prediction, our framework simultaneously reasons about multiple sets of tracking results, thereby increasing the likelihood of including accurate tracking results as inputs to prediction. We show that this framework improves overall prediction performance over the standard single-hypothesis tracking-prediction pipeline by up to 34.2% on the nuScenes dataset, with even more significant improvements (up to ~70%) when restricting the evaluation to challenging scenarios involving identity switches and fragments -- all with an acceptable computation overhead.","tags":[],"title":"MTP: Multi-Hypothesis Tracking and Prediction for Reduced Error Propagation","type":"publication"},{"authors":["Boris Ivanovic","Marco Pavone"],"categories":null,"content":"","date":1633616519,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1633616519,"objectID":"5f44dc5706c218f4690627221a0dea3c","permalink":"/publication/ivanovic.pavone.iv2022/","publishdate":"2021-10-07T10:21:59-04:00","relpermalink":"/publication/ivanovic.pavone.iv2022/","section":"publication","summary":"Detecting other agents and forecasting their behavior is an integral part of the modern robotic autonomy stack, especially in safety-critical scenarios entailing human-robot interaction such as autonomous driving. Due to the importance of these components, there has been a significant amount of interest and research in perception and trajectory forecasting, resulting in a wide variety of approaches. Common to most works, however, is the use of the same few accuracy-based evaluation metrics, e.g., intersection-over-union, displacement error, log-likelihood, etc. While these metrics are informative, they are task-agnostic and outputs that are evaluated as equal can lead to vastly different outcomes in downstream planning and decision making. In this work, we take a step back and critically assess current evaluation metrics, proposing task-aware metrics as a better measure of performance in systems where they are deployed. Experiments on an illustrative simulation as well as real-world autonomous driving data validate that our proposed task-aware metrics are able to account for outcome asymmetry and provide a better estimate of a model's closed-loop performance.","tags":[],"title":"Injecting Planning-Awareness into Prediction and Detection Evaluation","type":"publication"},{"authors":["Boris Ivanovic","Marco Pavone"],"categories":null,"content":"","date":1626877319,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1626877319,"objectID":"e2d662764e5ca9665ead879df1a8e885","permalink":"/publication/ivanovic.pavone.arxiv2021/","publishdate":"2021-07-21T10:21:59-04:00","relpermalink":"/publication/ivanovic.pavone.arxiv2021/","section":"publication","summary":"Forecasting the behavior of other agents is an integral part of the modern robotic autonomy stack, especially in safety-critical scenarios with human-robot interaction, such as autonomous driving. In turn, there has been a significant amount of interest and research in trajectory forecasting, resulting in a wide variety of approaches. Common to all works, however, is the use of the same few accuracy-based evaluation metrics, e.g., displacement error and log-likelihood. While these metrics are informative, they are task-agnostic and predictions that are evaluated as equal can lead to vastly different outcomes, e.g., in downstream planning and decision making. In this work, we take a step back and critically evaluate current trajectory forecasting metrics, proposing task-aware metrics as a better measure of performance in systems where prediction is being deployed. We additionally present one example of such a metric, incorporating planning-awareness within existing trajectory forecasting metrics.","tags":[],"title":"Rethinking Trajectory Forecasting Evaluation","type":"publication"}]